{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb125b2d-5a2f-463f-8953-7744dc887747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2db63a-cf70-4cb3-a94e-a2e80ce8a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로드 및 처리\n",
    "data = read_csv('price data.csv', sep=',')\n",
    "xy = data[['avgTemp', 'minTemp', 'maxTemp', 'rainFall', 'avgPrice']].to_numpy()\n",
    "\n",
    "x_data = xy[:, :-1]  # 평균 기온, 최저 기온, 최고 기온, 강수량\n",
    "y_data = xy[:, [-1]]  # 평균 가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d294adb1-c61c-4eb9-8a59-3f689188ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51dbff9-103e-4d2a-9268-5a863e85069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 \n",
    "x_data = x_data.astype(np.float64)\n",
    "y_data = y_data.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea58f0a-a6a9-407b-a89b-c7910551719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 편향 초기화\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "W = tf.Variable(initializer([4, 1], dtype=tf.float64), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1], dtype=tf.float64), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9e6902-1ee4-4638-bce6-318d6194f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 설정\n",
    "def hypothesis(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# 손실 함수\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "def cost_fn(X, Y):\n",
    "    return mse(Y, hypothesis(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa8329-338e-4779-98bc-2bd36ed26f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정 (0.0001)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d1f1a8b-3652-4ba3-957d-c0c1245f8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 186898.28125, 예측 값: [2490.30012986]\n",
      "Step 500, Loss: 186898.1875, 예측 값: [2490.30047434]\n",
      "Step 1000, Loss: 186898.203125, 예측 값: [2490.30080469]\n",
      "Step 1500, Loss: 186898.15625, 예측 값: [2490.30112103]\n",
      "Step 2000, Loss: 186898.125, 예측 값: [2490.30142349]\n",
      "Step 2500, Loss: 186898.09375, 예측 값: [2490.30171228]\n",
      "Step 3000, Loss: 186898.0625, 예측 값: [2490.3019875]\n",
      "Step 3500, Loss: 186898.015625, 예측 값: [2490.30224928]\n",
      "Step 4000, Loss: 186897.984375, 예측 값: [2490.30249778]\n",
      "Step 4500, Loss: 186897.96875, 예측 값: [2490.30273318]\n",
      "Step 5000, Loss: 186897.9375, 예측 값: [2490.30295559]\n",
      "Step 5500, Loss: 186897.875, 예측 값: [2490.30316516]\n",
      "Step 6000, Loss: 186897.859375, 예측 값: [2490.30336196]\n",
      "Step 6500, Loss: 186897.8125, 예측 값: [2490.30354615]\n",
      "Step 7000, Loss: 186897.796875, 예측 값: [2490.30371794]\n",
      "Step 7500, Loss: 186897.765625, 예측 값: [2490.30387742]\n",
      "Step 8000, Loss: 186897.75, 예측 값: [2490.3040247]\n",
      "Step 8500, Loss: 186897.71875, 예측 값: [2490.30415988]\n",
      "Step 9000, Loss: 186897.703125, 예측 값: [2490.30428313]\n",
      "Step 9500, Loss: 186897.671875, 예측 값: [2490.30439459]\n",
      "Step 10000, Loss: 186897.65625, 예측 값: [2490.30449438]\n",
      "Step 10500, Loss: 186897.640625, 예측 값: [2490.30458263]\n",
      "Step 11000, Loss: 186897.578125, 예측 값: [2490.30465942]\n",
      "Step 11500, Loss: 186897.5625, 예측 값: [2490.30472486]\n",
      "Step 12000, Loss: 186897.53125, 예측 값: [2490.30477913]\n",
      "Step 12500, Loss: 186897.515625, 예측 값: [2490.30482232]\n",
      "Step 13000, Loss: 186897.5, 예측 값: [2490.3048545]\n",
      "Step 13500, Loss: 186897.453125, 예측 값: [2490.30487588]\n",
      "Step 14000, Loss: 186897.453125, 예측 값: [2490.3048865]\n",
      "Step 14500, Loss: 186897.421875, 예측 값: [2490.30488651]\n",
      "Step 15000, Loss: 186897.390625, 예측 값: [2490.30487603]\n",
      "Step 15500, Loss: 186897.390625, 예측 값: [2490.30485516]\n",
      "Step 16000, Loss: 186897.359375, 예측 값: [2490.30482398]\n",
      "Step 16500, Loss: 186897.375, 예측 값: [2490.30478261]\n",
      "Step 17000, Loss: 186897.296875, 예측 값: [2490.30473117]\n",
      "Step 17500, Loss: 186897.28125, 예측 값: [2490.30466977]\n",
      "Step 18000, Loss: 186897.28125, 예측 값: [2490.30459851]\n",
      "Step 18500, Loss: 186897.265625, 예측 값: [2490.30451751]\n",
      "Step 19000, Loss: 186897.21875, 예측 값: [2490.30442683]\n",
      "Step 19500, Loss: 186897.21875, 예측 값: [2490.30432665]\n",
      "Step 20000, Loss: 186897.203125, 예측 값: [2490.30421697]\n",
      "Step 20500, Loss: 186897.1875, 예측 값: [2490.30409796]\n",
      "Step 21000, Loss: 186897.171875, 예측 값: [2490.30396969]\n",
      "Step 21500, Loss: 186897.15625, 예측 값: [2490.30383226]\n",
      "Step 22000, Loss: 186897.140625, 예측 값: [2490.30368579]\n",
      "Step 22500, Loss: 186897.109375, 예측 값: [2490.30353039]\n",
      "Step 23000, Loss: 186897.09375, 예측 값: [2490.30336608]\n",
      "Step 23500, Loss: 186897.109375, 예측 값: [2490.30319302]\n",
      "Step 24000, Loss: 186897.0625, 예측 값: [2490.3030113]\n",
      "Step 24500, Loss: 186897.0625, 예측 값: [2490.30282098]\n",
      "Step 25000, Loss: 186897.046875, 예측 값: [2490.30262219]\n",
      "Step 25500, Loss: 186897.015625, 예측 값: [2490.30241496]\n",
      "Step 26000, Loss: 186897.0, 예측 값: [2490.30219942]\n",
      "Step 26500, Loss: 186897.0, 예측 값: [2490.30197569]\n",
      "Step 27000, Loss: 186896.96875, 예측 값: [2490.3017438]\n",
      "Step 27500, Loss: 186896.96875, 예측 값: [2490.30150389]\n",
      "Step 28000, Loss: 186896.96875, 예측 값: [2490.30125602]\n",
      "Step 28500, Loss: 186896.9375, 예측 값: [2490.30100028]\n",
      "Step 29000, Loss: 186896.953125, 예측 값: [2490.30073675]\n",
      "Step 29500, Loss: 186896.90625, 예측 값: [2490.30046549]\n",
      "Step 30000, Loss: 186896.890625, 예측 값: [2490.30018654]\n",
      "Step 30500, Loss: 186896.890625, 예측 값: [2490.29990007]\n",
      "Step 31000, Loss: 186896.875, 예측 값: [2490.29960616]\n",
      "Step 31500, Loss: 186896.84375, 예측 값: [2490.29930486]\n",
      "Step 32000, Loss: 186896.84375, 예측 값: [2490.29899625]\n",
      "Step 32500, Loss: 186896.859375, 예측 값: [2490.29868041]\n",
      "Step 33000, Loss: 186896.828125, 예측 값: [2490.29835743]\n",
      "Step 33500, Loss: 186896.8125, 예측 값: [2490.29802736]\n",
      "Step 34000, Loss: 186896.828125, 예측 값: [2490.29769029]\n",
      "Step 34500, Loss: 186896.796875, 예측 값: [2490.2973463]\n",
      "Step 35000, Loss: 186896.78125, 예측 값: [2490.29699549]\n",
      "Step 35500, Loss: 186896.78125, 예측 값: [2490.29663787]\n",
      "Step 36000, Loss: 186896.765625, 예측 값: [2490.29627357]\n",
      "Step 36500, Loss: 186896.75, 예측 값: [2490.29590267]\n",
      "Step 37000, Loss: 186896.75, 예측 값: [2490.29552519]\n",
      "Step 37500, Loss: 186896.75, 예측 값: [2490.29514122]\n",
      "Step 38000, Loss: 186896.71875, 예측 값: [2490.29475085]\n",
      "Step 38500, Loss: 186896.6875, 예측 값: [2490.29435417]\n",
      "Step 39000, Loss: 186896.703125, 예측 값: [2490.29395117]\n",
      "Step 39500, Loss: 186896.671875, 예측 값: [2490.293542]\n",
      "Step 40000, Loss: 186896.671875, 예측 값: [2490.29312662]\n",
      "Step 40500, Loss: 186896.65625, 예측 값: [2490.29270519]\n",
      "Step 41000, Loss: 186896.65625, 예측 값: [2490.29227775]\n",
      "Step 41500, Loss: 186896.640625, 예측 값: [2490.2918444]\n",
      "Step 42000, Loss: 186896.640625, 예측 값: [2490.2914051]\n",
      "Step 42500, Loss: 186896.625, 예측 값: [2490.29096001]\n",
      "Step 43000, Loss: 186896.640625, 예측 값: [2490.29050917]\n",
      "Step 43500, Loss: 186896.609375, 예측 값: [2490.29005262]\n",
      "Step 44000, Loss: 186896.59375, 예측 값: [2490.28959045]\n",
      "Step 44500, Loss: 186896.609375, 예측 값: [2490.28912273]\n",
      "Step 45000, Loss: 186896.59375, 예측 값: [2490.28864948]\n",
      "Step 45500, Loss: 186896.578125, 예측 값: [2490.28817081]\n",
      "Step 46000, Loss: 186896.578125, 예측 값: [2490.28768676]\n",
      "Step 46500, Loss: 186896.578125, 예측 값: [2490.28719737]\n",
      "Step 47000, Loss: 186896.5625, 예측 값: [2490.28670275]\n",
      "Step 47500, Loss: 186896.5625, 예측 값: [2490.28620291]\n",
      "Step 48000, Loss: 186896.546875, 예측 값: [2490.28569785]\n",
      "Step 48500, Loss: 186896.53125, 예측 값: [2490.28518773]\n",
      "Step 49000, Loss: 186896.546875, 예측 값: [2490.28467257]\n",
      "Step 49500, Loss: 186896.515625, 예측 값: [2490.28415241]\n",
      "Step 50000, Loss: 186896.53125, 예측 값: [2490.28362734]\n",
      "Step 50500, Loss: 186896.53125, 예측 값: [2490.28309742]\n",
      "Step 51000, Loss: 186896.515625, 예측 값: [2490.28256269]\n",
      "Step 51500, Loss: 186896.5, 예측 값: [2490.28202315]\n",
      "Step 52000, Loss: 186896.484375, 예측 값: [2490.28147888]\n",
      "Step 52500, Loss: 186896.484375, 예측 값: [2490.28093002]\n",
      "Step 53000, Loss: 186896.484375, 예측 값: [2490.28037653]\n",
      "Step 53500, Loss: 186896.46875, 예측 값: [2490.27981844]\n",
      "Step 54000, Loss: 186896.484375, 예측 값: [2490.27925584]\n",
      "Step 54500, Loss: 186896.453125, 예측 값: [2490.27868876]\n",
      "Step 55000, Loss: 186896.453125, 예측 값: [2490.2781173]\n",
      "Step 55500, Loss: 186896.453125, 예측 값: [2490.27754149]\n",
      "Step 56000, Loss: 186896.453125, 예측 값: [2490.27696137]\n",
      "Step 56500, Loss: 186896.453125, 예측 값: [2490.27637696]\n",
      "Step 57000, Loss: 186896.421875, 예측 값: [2490.27578836]\n",
      "Step 57500, Loss: 186896.421875, 예측 값: [2490.27519557]\n",
      "Step 58000, Loss: 186896.40625, 예측 값: [2490.2745987]\n",
      "Step 58500, Loss: 186896.40625, 예측 값: [2490.27399773]\n",
      "Step 59000, Loss: 186896.40625, 예측 값: [2490.27339273]\n",
      "Step 59500, Loss: 186896.390625, 예측 값: [2490.27278376]\n",
      "Step 60000, Loss: 186896.390625, 예측 값: [2490.27217082]\n",
      "Step 60500, Loss: 186896.390625, 예측 값: [2490.271554]\n",
      "Step 61000, Loss: 186896.359375, 예측 값: [2490.27093334]\n",
      "Step 61500, Loss: 186896.375, 예측 값: [2490.2703088]\n",
      "Step 62000, Loss: 186896.375, 예측 값: [2490.2696805]\n",
      "Step 62500, Loss: 186896.34375, 예측 값: [2490.26904854]\n",
      "Step 63000, Loss: 186896.359375, 예측 값: [2490.26841285]\n",
      "Step 63500, Loss: 186896.34375, 예측 값: [2490.26777353]\n",
      "Step 64000, Loss: 186896.359375, 예측 값: [2490.26713065]\n",
      "Step 64500, Loss: 186896.34375, 예측 값: [2490.26648423]\n",
      "Step 65000, Loss: 186896.34375, 예측 값: [2490.26583429]\n",
      "Step 65500, Loss: 186896.34375, 예측 값: [2490.26518089]\n",
      "Step 66000, Loss: 186896.328125, 예측 값: [2490.26452405]\n",
      "Step 66500, Loss: 186896.328125, 예측 값: [2490.26386375]\n",
      "Step 67000, Loss: 186896.328125, 예측 값: [2490.26320016]\n",
      "Step 67500, Loss: 186896.3125, 예측 값: [2490.26253326]\n",
      "Step 68000, Loss: 186896.34375, 예측 값: [2490.26186306]\n",
      "Step 68500, Loss: 186896.3125, 예측 값: [2490.26118957]\n",
      "Step 69000, Loss: 186896.3125, 예측 값: [2490.26051297]\n",
      "Step 69500, Loss: 186896.296875, 예측 값: [2490.25983314]\n",
      "Step 70000, Loss: 186896.296875, 예측 값: [2490.25915019]\n",
      "Step 70500, Loss: 186896.296875, 예측 값: [2490.25846409]\n",
      "Step 71000, Loss: 186896.296875, 예측 값: [2490.25777489]\n",
      "Step 71500, Loss: 186896.28125, 예측 값: [2490.25708268]\n",
      "Step 72000, Loss: 186896.28125, 예측 값: [2490.25638749]\n",
      "Step 72500, Loss: 186896.28125, 예측 값: [2490.25568936]\n",
      "Step 73000, Loss: 186896.25, 예측 값: [2490.25498834]\n",
      "Step 73500, Loss: 186896.28125, 예측 값: [2490.25428451]\n",
      "Step 74000, Loss: 186896.265625, 예측 값: [2490.25357774]\n",
      "Step 74500, Loss: 186896.265625, 예측 값: [2490.25286813]\n",
      "Step 75000, Loss: 186896.25, 예측 값: [2490.25215569]\n",
      "Step 75500, Loss: 186896.25, 예측 값: [2490.25144057]\n",
      "Step 76000, Loss: 186896.25, 예측 값: [2490.2507227]\n",
      "Step 76500, Loss: 186896.25, 예측 값: [2490.25000221]\n",
      "Step 77000, Loss: 186896.25, 예측 값: [2490.24927901]\n",
      "Step 77500, Loss: 186896.234375, 예측 값: [2490.24855319]\n",
      "Step 78000, Loss: 186896.234375, 예측 값: [2490.24782482]\n",
      "Step 78500, Loss: 186896.234375, 예측 값: [2490.24709382]\n",
      "Step 79000, Loss: 186896.234375, 예측 값: [2490.24636035]\n",
      "Step 79500, Loss: 186896.21875, 예측 값: [2490.24562437]\n",
      "Step 80000, Loss: 186896.21875, 예측 값: [2490.24488593]\n",
      "Step 80500, Loss: 186896.21875, 예측 값: [2490.24414496]\n",
      "Step 81000, Loss: 186896.21875, 예측 값: [2490.24340161]\n",
      "Step 81500, Loss: 186896.203125, 예측 값: [2490.24265593]\n",
      "Step 82000, Loss: 186896.21875, 예측 값: [2490.24190781]\n",
      "Step 82500, Loss: 186896.21875, 예측 값: [2490.24115744]\n",
      "Step 83000, Loss: 186896.203125, 예측 값: [2490.2404047]\n",
      "Step 83500, Loss: 186896.203125, 예측 값: [2490.23964972]\n",
      "Step 84000, Loss: 186896.171875, 예측 값: [2490.2388925]\n",
      "Step 84500, Loss: 186896.1875, 예측 값: [2490.23813304]\n",
      "Step 85000, Loss: 186896.1875, 예측 값: [2490.23737135]\n",
      "Step 85500, Loss: 186896.171875, 예측 값: [2490.23660753]\n",
      "Step 86000, Loss: 186896.1875, 예측 값: [2490.23584166]\n",
      "Step 86500, Loss: 186896.1875, 예측 값: [2490.23507359]\n",
      "Step 87000, Loss: 186896.1875, 예측 값: [2490.23430343]\n",
      "Step 87500, Loss: 186896.171875, 예측 값: [2490.23353122]\n",
      "Step 88000, Loss: 186896.15625, 예측 값: [2490.23275699]\n",
      "Step 88500, Loss: 186896.171875, 예측 값: [2490.23198077]\n",
      "Step 89000, Loss: 186896.15625, 예측 값: [2490.23120254]\n",
      "Step 89500, Loss: 186896.15625, 예측 값: [2490.23042232]\n",
      "Step 90000, Loss: 186896.15625, 예측 값: [2490.22964014]\n",
      "Step 90500, Loss: 186896.15625, 예측 값: [2490.22885611]\n",
      "Step 91000, Loss: 186896.125, 예측 값: [2490.22807019]\n",
      "Step 91500, Loss: 186896.125, 예측 값: [2490.22728235]\n",
      "Step 92000, Loss: 186896.125, 예측 값: [2490.2264927]\n",
      "Step 92500, Loss: 186896.15625, 예측 값: [2490.2257013]\n",
      "Step 93000, Loss: 186896.125, 예측 값: [2490.22490806]\n",
      "Step 93500, Loss: 186896.125, 예측 값: [2490.22411302]\n",
      "Step 94000, Loss: 186896.125, 예측 값: [2490.2233162]\n",
      "Step 94500, Loss: 186896.09375, 예측 값: [2490.22251771]\n",
      "Step 95000, Loss: 186896.109375, 예측 값: [2490.22171753]\n",
      "Step 95500, Loss: 186896.109375, 예측 값: [2490.22091568]\n",
      "Step 96000, Loss: 186896.109375, 예측 값: [2490.22011204]\n",
      "Step 96500, Loss: 186896.09375, 예측 값: [2490.21930685]\n",
      "Step 97000, Loss: 186896.09375, 예측 값: [2490.21850006]\n",
      "Step 97500, Loss: 186896.09375, 예측 값: [2490.21769165]\n",
      "Step 98000, Loss: 186896.09375, 예측 값: [2490.21688168]\n",
      "Step 98500, Loss: 186896.09375, 예측 값: [2490.21607017]\n",
      "Step 99000, Loss: 186896.09375, 예측 값: [2490.21525711]\n",
      "Step 99500, Loss: 186896.09375, 예측 값: [2490.21444245]\n",
      "Step 100000, Loss: 186896.09375, 예측 값: [2490.21362638]\n",
      "학습된 모델을 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 학습 \n",
    "for step in range(100001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = cost_fn(x_data, y_data)\n",
    "    \n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step}, Loss: {cost.numpy()}, 예측 값: {hypothesis(x_data).numpy()[0]}\")\n",
    "\n",
    "# 저장\n",
    "ckpt = tf.train.Checkpoint(W=W, b=b)\n",
    "ckpt.save(\"./saved.ckpt\")\n",
    "print(\"학습된 모델을 저장했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
